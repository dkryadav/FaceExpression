{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FaceExpression.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Z75TsE_9LQ9G","colab_type":"code","colab":{}},"source":["import  numpy as  np\n","import pandas as pd\n","import os \n","import sys\n","from keras.models import Sequential\n","from keras.layers import Dense,Dropout,Activation,Flatten\n","from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,AveragePooling2D\n","from keras.losses import categorical_crossentropy\n","from keras.optimizers import Adam\n","from keras.regularizers import l2\n","from keras.utils import np_utils\n","from keras.models import model_from_json\n","from keras.preprocessing import image\n","from keras.layers import  Layer\n","from keras.preprocessing.image import ImageDataGenerator\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uZlEpHQFY8Af","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"3cdcad75-1a5c-4148-dab5-a8da240e1397","executionInfo":{"status":"ok","timestamp":1575884537013,"user_tz":-330,"elapsed":4945,"user":{"displayName":"DK Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mANZqHi9r0UFh5R8twAwzdHAU1HjvfSrRikzxjF=s64","userId":"07913290023415454504"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0rEklfDMQ7qn","colab_type":"code","outputId":"5a1aefb5-b5aa-46a6-f83d-35bb10f12c20","executionInfo":{"status":"ok","timestamp":1575884580929,"user_tz":-330,"elapsed":11802,"user":{"displayName":"DK Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mANZqHi9r0UFh5R8twAwzdHAU1HjvfSrRikzxjF=s64","userId":"07913290023415454504"}},"colab":{"base_uri":"https://localhost:8080/","height":428}},"source":["!cp drive/'My Drive'/fer2013.csv .\n","df=pd.read_csv('fer2013.csv')\n","print(df.info())\n","print(df[\"Usage\"].value_counts())\n","df.head()\n"],"execution_count":35,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 35887 entries, 0 to 35886\n","Data columns (total 3 columns):\n","emotion    35887 non-null int64\n","pixels     35887 non-null object\n","Usage      35887 non-null object\n","dtypes: int64(1), object(2)\n","memory usage: 841.2+ KB\n","None\n","Training       28709\n","PrivateTest     3589\n","PublicTest      3589\n","Name: Usage, dtype: int64\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>emotion</th>\n","      <th>pixels</th>\n","      <th>Usage</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n","      <td>Training</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n","      <td>Training</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n","      <td>Training</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n","      <td>Training</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6</td>\n","      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n","      <td>Training</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   emotion                                             pixels     Usage\n","0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n","1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n","2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n","3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n","4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"84Ri1P-HdJLY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"outputId":"0e69fafc-624b-450c-eb0f-faf57bdb6667","executionInfo":{"status":"ok","timestamp":1575884608082,"user_tz":-330,"elapsed":22173,"user":{"displayName":"DK Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mANZqHi9r0UFh5R8twAwzdHAU1HjvfSrRikzxjF=s64","userId":"07913290023415454504"}}},"source":["X_train,train_y,X_test,test_y=[],[],[],[]\n","\n","for index,row in df.iterrows():\n","  val = row['pixels'].split(\" \")\n","  try:\n","    if 'Training' in row['Usage']:\n","      X_train.append(np.array(val,'float32'))\n","      train_y.append(row['emotion'])\n","    elif 'PublicTest' in row['Usage']:\n","      X_test.append(np.array(val,'float32'))\n","      test_y.append(row['emotion'])\n","  except:\n","    print(f\"error occured at index:{index} and row:{row}\")\n","  \n","# print(f\"X_train sample data:{X_train[0:2]}\")\n","# print(f\"train_y sample data:{train_y[0:2]}\")\n","# print(f\"X_test sample data:{X_test[0:2]}\")\n","# print(f\"test_y sample data:{test_y[0:2]}\")\n","\n","X_train=np.array(X_train,'float32')\n","train_y=np.array(train_y,'float32')\n","X_test=np.array(X_test,'float32')\n","test_y=np.array(test_y,'float32')\n"],"execution_count":36,"outputs":[{"output_type":"stream","text":["[[ 70.  80.  82. ... 106. 109.  82.]\n"," [151. 150. 147. ... 193. 183. 184.]\n"," [231. 212. 156. ...  88. 110. 152.]\n"," ...\n"," [ 74.  81.  87. ... 188. 187. 187.]\n"," [222. 227. 203. ... 136. 136. 134.]\n"," [195. 199. 205. ...   6.  15.  38.]]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(28709, 2304)"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"AIQPTjZ_qI0R","colab_type":"code","colab":{}},"source":["# Normalising databetween 0 and 1\n","num_features = 64\n","num_labels = 7\n","batch_size = 64\n","epochs = 30\n","width,height = 48,48\n","\n","train_y = np_utils.to_categorical(train_y,num_classes=48)\n","test_y = np_utils.to_categorical(test_y,num_classes=48)\n","\n","\n","X_train-=np.mean(X_train,axis=0)\n","X_train/=np.std(X_train,axis=0)\n","\n","X_test-=np.mean(X_test,axis=0)\n","X_test/=np.std(X_test,axis=0)\n","\n","X_train = X_train.reshape(X_train.shape[0],width,height,1)\n","X_test = X_test.reshape(X_test.shape[0],width,height,1)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4NaCigZt5Dwc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":380},"outputId":"d2d2d39e-09bd-4b1d-b313-c1c6642af524","executionInfo":{"status":"error","timestamp":1575884672059,"user_tz":-330,"elapsed":1053,"user":{"displayName":"DK Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mANZqHi9r0UFh5R8twAwzdHAU1HjvfSrRikzxjF=s64","userId":"07913290023415454504"}}},"source":["#cnn Model\n","\n","model = Sequential()\n","# first CNN layer\n","model.add(Conv2D(num_features,kernel_size=(3,3),activation='relu',input_shape=(X_train.shape[1:])))\n","model.add(Conv2D(num_features,kernel_size=(3,3),activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n","model.add(Dropout(0.5))\n","\n","# Second CNN Layer\n","# model.add(Conv2D(2*num_features,(3,3), activation='relu'))\n","# model.add(Conv2D((2*num_features,(3,3),activation='relu'))\n","\n","# model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n","# model.add(Dropout(0.5))\n","\n","# Third CNN Layer\n","model.add(Conv2D(2*2*num_features,(3,3),activation='relu'))\n","model.add(Conv2D(2*3*num_features,(3,3),activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Flatten())\n","\n","model.add(Dense(2*2*2*2*num_features,activation='relu'))\n","model.add(Dropout(0.2))\n","\n","model.add(Dense(2*2*2*2*num_features,activation='relu'))\n","model.add(Dropout(0.2))\n","\n","model.add(Dense(num_labels,activation='softmax'))\n","\n","# model.summery()\n","gen = ImageDataGenerator()\n","train_generator = gen.flow(X_train, train_y, batch_size=batch_size)\n","\n","model.compile(loss=categorical_crossentropy,optimizer=Adam(),metrics=['accuracy'])\n","\n","model.fit(X_train,train_y,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(X_test,test_y),shuffle=True)\n","\n","# save model\n","fer_json = model.to_json()\n","with open(\"fer.json\",\"w\") as json_file:\n","  json_file.write(fer_json)\n","\n","model.save_weights(\"fer.h5\")"],"execution_count":40,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-f9b986feb1bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_22 to have 2 dimensions, but got array with shape (28709, 48, 48)"]}]},{"cell_type":"code","metadata":{"id":"ghRWw7ZfE4lK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6hzztCxE9AG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}